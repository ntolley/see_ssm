{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../code')\n",
    "# sys.path.append('../externals/mamba/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pickle\n",
    "import model_utils\n",
    "from torch import nn\n",
    "from mamba_ssm import Mamba\n",
    "\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device('cpu')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_fold = 0\n",
    "data_dict = model_utils.get_marker_decode_dataframes(noise_fold=noise_fold)\n",
    "wrist_df = data_dict['wrist_df']\n",
    "task_neural_df = data_dict['task_neural_df']\n",
    "notask_neural_df = data_dict['notask_neural_df']\n",
    "metadata = data_dict['metadata']\n",
    "cv_dict = data_dict['cv_dict']\n",
    "\n",
    "neuron_list = notask_neural_df['unit'].unique()\n",
    "\n",
    "notask_time_neural_mask = notask_neural_df['unit'] != 'time'\n",
    "notask_neural_df = notask_neural_df[notask_time_neural_mask]\n",
    "\n",
    "task_time_neural_mask = task_neural_df['unit'] != 'time'\n",
    "task_neural_df = task_neural_df[task_time_neural_mask]\n",
    "\n",
    "wrist_mask = wrist_df['name'] != 'time'\n",
    "wrist_df = wrist_df[wrist_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_frame_list = list()\n",
    "for layout_idx in range(1,5):\n",
    "    frame_data = np.load(f'../data/layout_frames/layout{layout_idx}_cam1.npy')\n",
    "    layout_frame_list.append(torch.tensor(frame_data).float())\n",
    "layout_frame_tensor = torch.stack(layout_frame_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_offset = 10 # try 50-150 ms offset\n",
    "window_size = 70\n",
    "label_col = 'layout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_cnn(nn.Module):\n",
    "    def __init__(self, output_size=4, device='cpu'):\n",
    "        super(model_cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5, stride=3)\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, stride=3)\n",
    "        self.fc1 = nn.Linear(1008, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #LSTM/GRU architecture for decoding\n",
    "# #RNN architecture for decoding kinematics\n",
    "# class model_mamba_cnn(nn.Module):\n",
    "#     def __init__(self, input_size, output_size, d_model, d_state=16, d_conv=4, expand=2, dropout=0.2, device=device,\n",
    "#                  cat_features=None, task_info=True):\n",
    "#         super(model_mamba_cnn, self).__init__()\n",
    "\n",
    "#         # Defining some parameters\n",
    "#         self.device = device\n",
    "#         self.dropout = dropout\n",
    "#         self.cat_features = cat_features\n",
    "#         self.task_info = task_info\n",
    "\n",
    "#         cnn_output_size = 4\n",
    "#         self.cnn = model_cnn(output_size=cnn_output_size).to(device)\n",
    "#         self.layout_indices = torch.tensor([1,2,3,4])\n",
    "#         self.layout_lookup = layout_frame_tensor\n",
    "\n",
    "#         self.input_size = input_size\n",
    "\n",
    "#         if self.cat_features is not None:\n",
    "#             self.num_cat_features = np.sum(self.cat_features).astype(int)\n",
    "#             self.input_size = self.input_size - self.num_cat_features\n",
    "\n",
    "            \n",
    "#         # self.fc = nn.Linear(in_features=d_model, out_features=output_size).to(device)\n",
    "#         self.fc1 = model_utils.model_ann(d_model, output_size, [100, 100]).to(device)\n",
    "#         self.fc2 = nn.Linear(in_features=output_size, out_features=output_size).to(device)\n",
    "#         self.dropout = nn.Dropout(p=self.dropout)\n",
    "\n",
    "#         # self.fc = nn.Linear((input_), output_size)\n",
    "#         self.mamba = Mamba(d_model=d_model, d_state=d_state, d_conv=d_conv, expand=expand).to(device)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "\n",
    "#         if not self.task_info:\n",
    "#             x[:, :, self.cat_features] = 0.0\n",
    "#             x[:,:,-np.random.choice([1,2,3,4])] = 1.0\n",
    "\n",
    "        \n",
    "\n",
    "#         batch_size = x.size(0)\n",
    "\n",
    "#         out = self.mamba(x)\n",
    "#         out = self.dropout(out)\n",
    "#         out = self.fc1(out)\n",
    "#         out = self.fc2(out)\n",
    "#         return out, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM/GRU architecture for decoding\n",
    "#RNN architecture for decoding kinematics\n",
    "class model_lstm(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers, dropout, device, bidirectional=False,\n",
    "                 cat_features=None, task_info=True):\n",
    "        super(model_lstm, self).__init__()\n",
    "\n",
    "        #multiplier based on bidirectional parameter\n",
    "        if bidirectional:\n",
    "            num_directions = 2\n",
    "        else:\n",
    "            num_directions = 1\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim       \n",
    "        self.n_layers = n_layers * num_directions\n",
    "        self.device = device\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        self.cat_features = cat_features\n",
    "        self.input_size = input_size\n",
    "        self.task_info = task_info\n",
    "\n",
    "        self.cnn_output_size = 10\n",
    "        self.cnn = model_cnn(output_size=self.cnn_output_size).to(device)\n",
    "        self.input_size = self.input_size + (self.cnn_output_size - np.sum(self.cat_features))\n",
    "\n",
    "        self.layout_lookup = layout_frame_tensor\n",
    "        self.layout_embedding = torch.randn((4, self.cnn_output_size,))\n",
    "\n",
    "            \n",
    "        self.fc = nn.Linear(self.hidden_dim * num_directions, output_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_dim, n_layers, batch_first=True, dropout=dropout, bidirectional=bidirectional) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "\n",
    "        if not self.task_info:\n",
    "            x[:, :, self.cat_features] = 0.0\n",
    "            x[:,:,-np.random.choice([1,2,3,4])] = 1.0\n",
    "\n",
    "        layout_embedding = self.cnn(self.layout_lookup)\n",
    "\n",
    "        layout_indices = x[:, 0, self.cat_features].nonzero(as_tuple=True)[1]\n",
    "        layout_inputs = layout_embedding[layout_indices]\n",
    "        layout_inputs = layout_inputs.repeat(x.shape[1], 1, 1).transpose(1,0)\n",
    "\n",
    "        x = x[:, :, ~self.cat_features]\n",
    "        x = torch.concat([x, layout_inputs], dim=2)\n",
    "\n",
    "        hidden, cell = self.init_hidden(batch_size)\n",
    "\n",
    "        out_lstm, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "\n",
    "        out_final = out_lstm.contiguous()\n",
    "        out_final = self.fc(out_final)\n",
    "        return out_final, hidden, cell\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data.to(self.device)\n",
    "\n",
    "        #LSTM initialization\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device)\n",
    "        cell = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device) + 1\n",
    "\n",
    "        return hidden, cell\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rnn(pred_df, neural_df, neural_offset, cv_dict, metadata, task_info=True,\n",
    "            window_size=50, num_cat=0, label_col=None, flip_outputs=False, temperature=0.1, dropout=0.5):\n",
    "    exclude_processing = None\n",
    "    criterion = model_utils.mse\n",
    "    if num_cat > 0:\n",
    "        exclude_processing = np.zeros(len(neural_df['unit'].unique()))\n",
    "        exclude_processing[-num_cat:] = np.ones(num_cat)\n",
    "        exclude_processing = exclude_processing.astype(bool)\n",
    "\n",
    "    # else:\n",
    "    #     criterion = mse\n",
    "\n",
    "    data_arrays, generators = model_utils.make_generators(\n",
    "    pred_df, neural_df, neural_offset, cv_dict, metadata, exclude_neural=exclude_processing,\n",
    "    window_size=window_size, flip_outputs=flip_outputs, batch_size=1000, label_col=label_col, fold=2)\n",
    "\n",
    "    # Unpack tuple into variables\n",
    "    training_set, validation_set, testing_set = data_arrays\n",
    "    training_generator, training_eval_generator, validation_generator, testing_generator = generators\n",
    "\n",
    "    X_train_data = training_set[:][0][:,-1,:].detach().cpu().numpy()\n",
    "    y_train_data = training_set[:][1][:,-1,:].detach().cpu().numpy()\n",
    "\n",
    "    X_test_data = testing_set[:][0][:,-1,:].detach().cpu().numpy()\n",
    "    y_test_data = testing_set[:][1][:,-1,:].detach().cpu().numpy()\n",
    "\n",
    "    #Define hyperparameters\n",
    "    lr = 1e-3\n",
    "    # weight_decay = 1e-4\n",
    "    weight_decay = 1e-4\n",
    "    hidden_dim = 600\n",
    "    n_layers = 2\n",
    "    max_epochs = 1000\n",
    "    input_size = X_train_data.shape[1] \n",
    "    output_size = y_train_data.shape[1] \n",
    "\n",
    "    # model_rnn = model_mamba_cnn(input_size, output_size, d_model=input_size,\n",
    "    #                         d_state=128, d_conv=4, expand=2, cat_features=exclude_processing,\n",
    "    #                         task_info=task_info)\n",
    "\n",
    "    model_rnn = model_lstm(input_size, output_size, hidden_dim, n_layers, dropout,\n",
    "                                    device, cat_features=exclude_processing, task_info=task_info).to(device)\n",
    "\n",
    "\n",
    "    # Define Loss, Optimizerints h\n",
    "    optimizer = torch.optim.Adam(model_rnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    #Train model\n",
    "    loss_dict = model_utils.train_validate_model(model_rnn, optimizer, criterion, max_epochs, training_generator, validation_generator, device, 10, 5)\n",
    "\n",
    "    #Evaluate trained model\n",
    "    rnn_train_pred = model_utils.evaluate_model(model_rnn, training_eval_generator, device)\n",
    "    rnn_test_pred = model_utils.evaluate_model(model_rnn, testing_generator, device)\n",
    "\n",
    "    rnn_train_corr = model_utils.matrix_corr(rnn_train_pred, y_train_data)\n",
    "    rnn_test_corr = model_utils.matrix_corr(rnn_test_pred, y_test_data)\n",
    "\n",
    "    res_dict = {'loss_dict': loss_dict,\n",
    "                'train_pred': rnn_train_pred, 'test_pred': rnn_test_pred,\n",
    "                'train_corr': rnn_train_corr, 'test_corr': rnn_test_corr}\n",
    "\n",
    "    return model_rnn, res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    }
   ],
   "source": [
    "# func_dict = {'wiener': contrastive_functions.run_wiener, 'rnn': contrastive_functions.run_rnn}\n",
    "func_dict = {'rnn': run_rnn}\n",
    "\n",
    "fpath = '../data/neuron_num_results/'\n",
    "\n",
    "num_repeats = 1\n",
    "\n",
    "num_neuron_results_dict = {'noise_fold': noise_fold}\n",
    "\n",
    "\n",
    "# df_dict = {'task': {'df': task_neural_df, 'task_info': True, 'num_cat': 4, 'flip_outputs': True},\n",
    "#             'notask': {'df': notask_neural_df, 'task_info': False, 'num_cat': 0, 'flip_outputs': True}}\n",
    "\n",
    "df_dict = {'task': {'df': task_neural_df, 'task_info': True, 'num_cat': 4, 'flip_outputs': True},\n",
    "            'notask': {'df': task_neural_df, 'task_info': False, 'num_cat': 4, 'flip_outputs': True}}\n",
    "\n",
    "decode_results = dict()\n",
    "for func_name, func in func_dict.items():\n",
    "    decode_results[func_name] = dict()\n",
    "    for df_type, pred_df in df_dict.items():\n",
    "        # print(f'{func_name}_{df_type} num_neurons: {num_neurons}; repeat {repeat_idx}')\n",
    "\n",
    "        model, res_dict = func(wrist_df, pred_df['df'], neural_offset, cv_dict, metadata, task_info=pred_df['task_info'],\n",
    "                                window_size=window_size, num_cat=pred_df['num_cat'], label_col=label_col, flip_outputs=pred_df['flip_outputs'])\n",
    "\n",
    "        decode_results[func_name][df_type] = res_dict\n",
    "\n",
    "        # # Save results on every loop in case early stop\n",
    "        # num_neuron_results_dict[f'repeat_{repeat_idx}'][f'num_neuron_{num_neurons}'] = decode_results\n",
    "        # # #Save metadata\n",
    "        # output = open(f'{fpath}num_neuron_results.pkl', 'wb')\n",
    "        # pickle.dump(num_neuron_results_dict, output)\n",
    "        # output.close()\n",
    "\n",
    "        # if func_name == 'rnn':\n",
    "        #     torch.save(model.state_dict(), f'{fpath}models/{df_type}_neurons{num_neurons}_repeat{repeat_idx}.pt')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_type = 'rnn'\n",
    "cond1, cond2 = 'notask', 'task'\n",
    "\n",
    "labelsize=18\n",
    "ticksize=15\n",
    "\n",
    "nolayout_test_corr = decode_results[decoder_type][cond1]['test_corr']\n",
    "all_test_corr = decode_results[decoder_type][cond2]['test_corr']\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "plot_data = np.stack([nolayout_test_corr, all_test_corr])\n",
    "_ = plt.plot(plot_data, color='k', linewidth=2, alpha=0.8)\n",
    "plt.xticks([0, 1], labels=['neural', 'neural + objlayout'], fontsize=labelsize)\n",
    "plt.yticks(fontsize=ticksize)\n",
    "plt.ylabel('Correlation', fontsize=labelsize)\n",
    "plt.violinplot(nolayout_test_corr, positions=[0], showmeans=False,showextrema=False)\n",
    "plt.violinplot(all_test_corr, positions=[1], showmeans=False,showextrema=False)\n",
    "# plt.title('All Marker Decoding', fontsize=16)\n",
    "# plt.ylim([-0.05,0.9])\n",
    "# plt.savefig(f'../figures/mamba_layout_violin.png')\n",
    "# plt.savefig(f'../figures/lstm_layout_violin.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_processing = None\n",
    "\n",
    "data_arrays, generators = model_utils.make_generators(\n",
    "wrist_df, task_neural_df, neural_offset, cv_dict, metadata, exclude_neural=exclude_processing,\n",
    "window_size=window_size, flip_outputs=True, batch_size=1000, label_col=label_col, fold=2)\n",
    "\n",
    "# Unpack tuple into variables\n",
    "training_set, validation_set, testing_set = data_arrays\n",
    "training_generator, training_eval_generator, validation_generator, testing_generator = generators\n",
    "\n",
    "X_train_data = training_set[:][0][:,-1,:].detach().cpu().numpy()\n",
    "y_train_data = training_set[:][1][:,-1,:].detach().cpu().numpy()\n",
    "\n",
    "X_test_data = testing_set[:][0][:,-1,:].detach().cpu().numpy()\n",
    "y_test_data = testing_set[:][1][:,-1,:].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_list = ['carpal', 'elbowTip', 'fnum', 'indexDis',\n",
    "       'indexMid', 'indexProx', 'indexTip', 'middleDis', 'middleMid',\n",
    "       'middleProx', 'middleTip', 'pinkyDis', 'pinkyMid', 'pinkyProx',\n",
    "       'pinkyTip', 'ringDis', 'ringMid', 'ringProx', 'ringTip',\n",
    "       'thumbDis', 'thumbMid', 'thumbProx']\n",
    "labelsize = 15\n",
    "ticksize=10\n",
    "time_offset = 500\n",
    "\n",
    "bounds = list(range(0+time_offset,1000+time_offset))\n",
    "x_times = np.arange(len(bounds)) / 100 # Sampling rate=100 Hz\n",
    "\n",
    "# repeat_name = 'repeat_0'\n",
    "# num_neuron_name = 'num_neuron_15'\n",
    "\n",
    "plt.figure(figsize=(8,len(marker_list) * 5))\n",
    "\n",
    "marker_counter = 0\n",
    "coord_idx = 0\n",
    "coord_names = ['x','y','z']\n",
    "for mrk_idx in range(len(marker_list) * 3):\n",
    "    if mrk_idx % 3 == 0:\n",
    "        marker_counter += 1\n",
    "        coord_idx = 0\n",
    "    coord_idx += 1\n",
    "\n",
    "    plt.subplot(len(marker_list) * 3,1,mrk_idx+1)\n",
    "    notask_corr = np.corrcoef(y_test_data[:,mrk_idx], decode_results['rnn']['notask']['test_pred'][:,mrk_idx])\n",
    "    task_corr = np.corrcoef(y_test_data[:,mrk_idx], decode_results['rnn']['task']['test_pred'][:,mrk_idx])\n",
    "\n",
    "\n",
    "    plt.plot(x_times, y_test_data[bounds,mrk_idx], color='k', label='DLC Marker')\n",
    "    plt.plot(x_times, decode_results['rnn']['notask']['test_pred'][bounds,mrk_idx], color='grey', label='RNN Pred')\n",
    "    plt.plot(x_times, decode_results['rnn']['task']['test_pred'][bounds,mrk_idx], color=f'C{marker_counter-1}')\n",
    "\n",
    "    plt.xticks(fontsize=ticksize)\n",
    "    plt.yticks(fontsize=ticksize)\n",
    "    plt.title(f'{marker_list[marker_counter-1]}_{coord_names[coord_idx-1]}; notask corr: {notask_corr[0,1]:.2f};  task corr: {task_corr[0,1]:.2f}', fontsize=20)\n",
    "plt.xlabel('Time (s)', fontsize=labelsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('../figures/mamba_layout_trajectory.png')\n",
    "# plt.savefig('../figures/lstm_layout_trajectory.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_diff = all_test_corr - nolayout_test_corr\n",
    "\n",
    "ticksize=13\n",
    "plt.figure(figsize=(10,3))\n",
    "bins=np.linspace(-0.15, 0.15, 40)\n",
    "_ = plt.hist(corr_diff, bins=bins, width=0.004)\n",
    "plt.axvline(x=0, color='k')\n",
    "plt.xlabel('Correlation difference (layout - no layout)', fontsize=labelsize)\n",
    "plt.xticks(fontsize=ticksize)\n",
    "plt.yticks(fontsize=ticksize)\n",
    "# plt.savefig('../figures/mamba_layout_hist.png')\n",
    "# plt.savefig('../figures/lstm_layout_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "see",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
